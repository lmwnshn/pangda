{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc60211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect, MetaData\n",
    "from sqlalchemy.engine.reflection import Inspector\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from scipy.stats._continuous_distns import _distn_names\n",
    "import scipy.stats\n",
    "import warnings\n",
    "\n",
    "from distfit import distfit\n",
    "import numpy as np\n",
    "\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbcb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_tables = {}\n",
    "scaled_tables_order = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d5a134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'region'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptf r_regionkey float64\n",
      "const r_name object\n",
      "const r_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 10\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nation'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptf n_nationkey float64\n",
      "const n_name object\n",
      "fkey n_regionkey Int64\n",
      "const n_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 50\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'supplier'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distfit s_suppkey Float64\n",
      "const s_name object\n",
      "const s_address object\n",
      "fkey s_nationkey Int64\n",
      "const s_phone object\n",
      "distfit s_acctbal Float64\n",
      "const s_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 2000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'part'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distfit p_partkey Float64\n",
      "const p_name object\n",
      "const p_mfgr object\n",
      "const p_brand object\n",
      "const p_type object\n",
      "distfit p_size Float64\n",
      "const p_container object\n",
      "distfit p_retailprice Float64\n",
      "const p_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 40000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'partsupp'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey ps_partkey Int64\n",
      "fkey ps_suppkey Int64\n",
      "distfit ps_availqty Float64\n",
      "distfit ps_supplycost Float64\n",
      "const ps_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 160000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'orders'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distfit o_orderkey Float64\n",
      "distfit o_custkey Float64\n",
      "const o_orderstatus object\n",
      "distfit o_totalprice Float64\n",
      "distfit o_orderdate Float64\n",
      "const o_orderpriority object\n",
      "const o_clerk object\n",
      "const o_shippriority int64\n",
      "const o_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 300000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lineitem'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey l_orderkey Int64\n",
      "fkey l_partkey Int64\n",
      "fkey l_suppkey Int64\n",
      "distfit l_linenumber Float64\n",
      "distfit l_quantity Float64\n",
      "distfit l_extendedprice Float64\n",
      "distfit l_discount Float64\n",
      "distfit l_tax Float64\n",
      "const l_returnflag object\n",
      "const l_linestatus object\n",
      "distfit l_shipdate Float64\n",
      "distfit l_commitdate Float64\n",
      "distfit l_receiptdate Float64\n",
      "const l_shipinstruct object\n",
      "const l_shipmode object\n",
      "const l_comment object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 1201144\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'warehouse'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptf w_id int64\n",
      "const w_ytd float64\n",
      "const w_tax float64\n",
      "const w_name object\n",
      "const w_street_1 object\n",
      "const w_street_2 object\n",
      "const w_city object\n",
      "const w_state object\n",
      "const w_zip object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 2\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stock'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey s_w_id Int64\n",
      "fkey s_i_id Int64\n",
      "distfit s_quantity Float64\n",
      "const s_ytd float64\n",
      "const s_order_cnt int64\n",
      "const s_remote_cnt int64\n",
      "const s_data object\n",
      "const s_dist_01 object\n",
      "const s_dist_02 object\n",
      "const s_dist_03 object\n",
      "const s_dist_04 object\n",
      "const s_dist_05 object\n",
      "const s_dist_06 object\n",
      "const s_dist_07 object\n",
      "const s_dist_08 object\n",
      "const s_dist_09 object\n",
      "const s_dist_10 object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 200000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'item'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distfit i_id Float64\n",
      "const i_name object\n",
      "distfit i_price Float64\n",
      "const i_data object\n",
      "distfit i_im_id Float64\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 200000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'district'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey d_w_id Int64\n",
      "ptf d_id float64\n",
      "const d_ytd float64\n",
      "distfit d_tax Float64\n",
      "const d_next_o_id int64\n",
      "const d_name object\n",
      "const d_street_1 object\n",
      "const d_street_2 object\n",
      "const d_city object\n",
      "const d_state object\n",
      "const d_zip object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 20\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey h_c_id Int64\n",
      "fkey h_c_d_id Int64\n",
      "fkey h_c_w_id Int64\n",
      "fkey h_d_id Int64\n",
      "fkey h_w_id Int64\n",
      "distfit h_date Float64\n",
      "const h_amount float64\n",
      "const h_data object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 60000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'customer'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey c_w_id Int64\n",
      "fkey c_d_id Int64\n",
      "distfit c_id Float64\n",
      "distfit c_discount Float64\n",
      "const c_credit object\n",
      "const c_last object\n",
      "const c_first object\n",
      "const c_credit_lim float64\n",
      "const c_balance float64\n",
      "const c_ytd_payment float64\n",
      "const c_payment_cnt int64\n",
      "const c_delivery_cnt int64\n",
      "const c_street_1 object\n",
      "const c_street_2 object\n",
      "const c_city object\n",
      "const c_state object\n",
      "const c_zip object\n",
      "const c_phone object\n",
      "distfit c_since Float64\n",
      "const c_middle object\n",
      "const c_data object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 60000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oorder'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey o_w_id Int64\n",
      "fkey o_d_id Int64\n",
      "distfit o_id Float64\n",
      "fkey o_c_id Int64\n",
      "distfit o_carrier_id Float64\n",
      "distfit o_ol_cnt Float64\n",
      "const o_all_local int64\n",
      "distfit o_entry_d Float64\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 60000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'new_order'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey no_w_id Int64\n",
      "fkey no_d_id Int64\n",
      "fkey no_o_id Int64\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 18000\n",
      "Final fix of datatypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'order_line'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkey ol_w_id Int64\n",
      "fkey ol_d_id Int64\n",
      "fkey ol_o_id Int64\n",
      "distfit ol_number Float64\n",
      "fkey ol_i_id Int64\n",
      "distfit ol_delivery_d Float64\n",
      "distfit ol_amount Float64\n",
      "fkey ol_supply_w_id Int64\n",
      "const ol_quantity float64\n",
      "const ol_dist_info object\n",
      "Fixing datatypes.\n",
      "Fixing multicol fkeys.\n",
      "Result: 600080\n",
      "Final fix of datatypes.\n"
     ]
    }
   ],
   "source": [
    "def resize_db(engine, scalefactor=2):\n",
    "    global scaled_tables\n",
    "    inspector = Inspector.from_engine(engine)\n",
    "    table_names = inspector.get_table_names()\n",
    "    \n",
    "    # All the tables must be processed.\n",
    "    \n",
    "    workqueue = queue.Queue()\n",
    "    for table_name in table_names:\n",
    "        workqueue.put(table_name)\n",
    "\n",
    "    while not workqueue.empty():\n",
    "        table_name = workqueue.get()\n",
    "        display(table_name)\n",
    "        \n",
    "        # Get schema information on primary keys and foreign keys.  \n",
    "        info_pk = inspector.get_pk_constraint(table_name)\n",
    "        info_unique = inspector.get_unique_constraints(table_name)\n",
    "        info_fk = inspector.get_foreign_keys(table_name)\n",
    "        \n",
    "        pkey_columns = info_pk['constrained_columns']\n",
    "        fkey_columns = {\n",
    "            src_col: (fk['referred_table'], dst_col)\n",
    "            for fk in info_fk\n",
    "            for src_col, dst_col in zip(fk['constrained_columns'], fk['referred_columns'])\n",
    "        }\n",
    "        unique_columns_list = [ukey['column_names'] for ukey in info_unique]\n",
    "        if len(unique_columns_list) > 0:\n",
    "            raise Exception(f\"Can't handle unique: {unique_columns_list}\")\n",
    "        \n",
    "        # If this table has a foreign key constraint on a yet-unscaled table,\n",
    "        # then this table cannot be processed yet.\n",
    "        # Move this table to the back of the queue.\n",
    "        # TODO(WAN): Replace with a topological sort on fkey dependencies.\n",
    "        skippy = False\n",
    "        for fkey_src, fkey_dst in fkey_columns.items():\n",
    "            fkey_table_name = fkey_dst[0]\n",
    "            if fkey_table_name not in scaled_tables:\n",
    "                skippy = True\n",
    "                print(f'Moving {table_name} to end because of {fkey_dst}.')\n",
    "        if skippy:\n",
    "            workqueue.put(table_name)\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "        scaled_data = {}\n",
    "        scaled_len = int(df.shape[0] * scalefactor)\n",
    "\n",
    "        to_generate = scaled_len\n",
    "\n",
    "        for col in df.columns:\n",
    "            series = df[col]\n",
    "\n",
    "            is_unique = any(col in unique_columns for unique_columns in unique_columns_list)\n",
    "            if is_unique:\n",
    "                is_fkey = col in fkey_columns\n",
    "                if is_fkey:\n",
    "                    fkey_table, fkey_col = fkey_columns[col]\n",
    "                    scaled_data[col] = scaled_tables[fkey_table][fkey_col].sample(n=to_generate, replace=True).reset_index(drop=True)\n",
    "                else:\n",
    "                    scaled_data[col] = series.max() + np.arange(1, 1 + to_generate)\n",
    "                print('unique', col, scaled_data[col].dtype)\n",
    "                assert len(scaled_data[col]) == to_generate\n",
    "                continue\n",
    "\n",
    "            # For columns that are a foreign key, values must be drawn from the referenced table.\n",
    "            is_fkey = col in fkey_columns\n",
    "            if is_fkey:\n",
    "                fkey_table_name, fkey_table_col = fkey_columns[col]\n",
    "                fkey_values = scaled_tables[fkey_table_name][fkey_table_col]\n",
    "                sample = fkey_values.sample(n=to_generate, replace=True).reset_index(drop=True)\n",
    "                scaled_data[col] = sample\n",
    "                print('fkey', col, scaled_data[col].dtype)\n",
    "                assert len(scaled_data[col]) == to_generate\n",
    "                continue\n",
    "\n",
    "            # For columns that are a primary key and monotonically increasing, build a linear model.\n",
    "            is_pkey = col in pkey_columns\n",
    "            is_mono_inc = series.is_monotonic_increasing\n",
    "            if is_pkey and is_mono_inc:\n",
    "                # Edge case, e.g., TPC-C warehouse w_id SF1 has one row.\n",
    "                if series.shape[0] == 1:\n",
    "                    scaled_data[col] = series.max() + np.arange(1, 1 + to_generate)\n",
    "                else:\n",
    "                    ptf = PolynomialTrendForecaster(degree=1)\n",
    "                    ptf.fit(series)\n",
    "                    horizon = np.arange(1, 1 + to_generate)\n",
    "                    predicted_ptf = ptf.predict(horizon)\n",
    "                    scaled_data[col] = predicted_ptf.reset_index(drop=True)\n",
    "                print('ptf', col, scaled_data[col].dtype)\n",
    "                assert len(scaled_data[col]) == to_generate\n",
    "                continue\n",
    "\n",
    "            # For columns that are all constant or all NA, keep it that way.\n",
    "            # For columns that are object-typed, e.g., strings, sample the original values.\n",
    "            # The code looks identical for both.\n",
    "            is_constant = series.nunique() == 1\n",
    "            is_na = all(series.isna())\n",
    "            is_obj = series.dtype == \"object\"\n",
    "            if is_constant or is_na or is_obj:\n",
    "                sample = series.sample(n=to_generate, replace=True).reset_index(drop=True)\n",
    "                scaled_data[col] = sample\n",
    "                print('const', col, scaled_data[col].dtype)\n",
    "                assert len(scaled_data[col]) == to_generate\n",
    "                continue\n",
    "\n",
    "            # Otherwise, we sure hope we have a numeric column...\n",
    "            # Otherwise, we hope we have a numeric column that we can fit a distribution to.\n",
    "            # We then draw samples from that distribution.\n",
    "\n",
    "            dist = distfit()\n",
    "            dist.fit_transform(series.dropna(), verbose=1)\n",
    "            generated = pd.Series(dist.generate(to_generate, verbose=1)).astype('Float64')\n",
    "            na_frac = series.isna().sum() / series.shape[0]\n",
    "            scaled_data[col] = generated\n",
    "            indexes = scaled_data[col].sample(frac=na_frac).index\n",
    "            scaled_data[col].iloc[indexes] = pd.NA\n",
    "            print('distfit', col, scaled_data[col].dtype)\n",
    "            assert len(scaled_data[col]) == to_generate\n",
    "\n",
    "        assert set(scaled_data.keys()) == set(df.columns)\n",
    "        scaled_df = pd.DataFrame(scaled_data)\n",
    "\n",
    "        # Fix up datatypes.\n",
    "        print('Fixing datatypes.')\n",
    "        for col in inspector.get_columns(table_name):\n",
    "            col_name = col['name']\n",
    "            if col['type'].python_type == int:\n",
    "                scaled_df[col_name] = scaled_df[col_name].round(0).astype('Int64', errors='ignore')\n",
    "\n",
    "        print('Fixing multicol fkeys.')\n",
    "        for fk in info_fk:\n",
    "            # Pick one to be a source of truth.\n",
    "            fkc = list(zip(fk['constrained_columns'], fk['referred_columns']))\n",
    "            choice = random.choice(fkc)\n",
    "            fkc.remove(choice)\n",
    "            if len(fkc) == 0:\n",
    "                # Not multicol.\n",
    "                continue\n",
    "\n",
    "            src_main_col, dst_main_col = choice\n",
    "            src_other_cols = [c[0] for c in fkc]\n",
    "            dst_other_cols = [c[1] for c in fkc]\n",
    "            dfo = scaled_tables[fk['referred_table']]\n",
    "\n",
    "            idxs = []\n",
    "            for val in scaled_df[src_main_col]:\n",
    "                matches = dfo[dst_main_col] == val\n",
    "                idx = np.random.choice(matches.index[matches.values].values)\n",
    "                idxs.append(idx)\n",
    "            scaled_df[src_other_cols] = dfo.iloc[idxs][dst_other_cols].reset_index(drop=True)\n",
    "\n",
    "#             print('Pruning uniques.')\n",
    "#             for unique_columns in unique_columns_list + [pkey_columns]:\n",
    "#                 raise Exception('gg')\n",
    "#                 # TODO(WAN): !! this doesn't actually work! violation?\n",
    "#                 print('predrop', scaled_df.shape)\n",
    "#                 scaled_df.drop_duplicates(subset=unique_columns, inplace=True, ignore_index=True)\n",
    "#                 print('postdrop', scaled_df.shape)\n",
    "\n",
    "        print(f'Result: {scaled_df.shape[0]}')\n",
    "            \n",
    "        print('Final fix of datatypes.')\n",
    "        for col in inspector.get_columns(table_name):\n",
    "            col_name = col['name']\n",
    "            if str(col['type']) in ['DATE', 'TIMESTAMP']:\n",
    "                scaled_df[col_name] = pd.to_datetime(scaled_df[col_name])\n",
    "            \n",
    "        scaled_tables[table_name] = scaled_df\n",
    "        scaled_tables_order.append(table_name)\n",
    "\n",
    "# Unfortunately, stream_results breaks pandas to_sql.\n",
    "execution_options = {'stream_results': True}\n",
    "engine = create_engine('postgresql://benchbaseuser:benchbasepass@localhost/benchbase', execution_options=execution_options)\n",
    "resize_db(engine, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349579a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"item_pkey\"\nDETAIL:  Key (i_id)=(41044) already exists.\n\n[SQL: INSERT INTO item (i_id, i_name, i_price, i_data, i_im_id) VALUES (%(i_id)s, %(i_name)s, %(i_price)s, %(i_data)s, %(i_im_id)s)]\n[parameters: ({'i_id': 71873, 'i_name': 'tdjtylgvvwtwgyxhj', 'i_price': 72.91484610436777, 'i_data': 'hdduohbpzmtpqcxxiaycdzefgntboifehfgalndewaznutnin', 'i_im_id': 8609}, {'i_id': 43783, 'i_name': 'xseowiihvcuoyjuncbdzril', 'i_price': 98.10781507092857, 'i_data': 'hdbklonizbqtywyjdxdvrbsbvfuk', 'i_im_id': 8364}, {'i_id': 47077, 'i_name': 'uqwguivweumqsbcntrvpglz', 'i_price': 65.60060731611074, 'i_data': 'jsuktpybndupslilzuyburjazxygajpbhunvloc', 'i_im_id': 749}, {'i_id': 50014, 'i_name': 'npyhkbushoybrzv', 'i_price': 72.86345612233407, 'i_data': 'auyhziljwvayekrxntiwdnazcynexga', 'i_im_id': 2899}, {'i_id': 85504, 'i_name': 'fsbwffneoyzyqriemtlgerz', 'i_price': 14.49870262950143, 'i_data': 'tyqyiwdkxxaqkyxleppjommfdzyojoqqyxfx', 'i_im_id': 4390}, {'i_id': 86847, 'i_name': 'knnjczehdtwwockwpv', 'i_price': 28.037320560710167, 'i_data': 'jncaoukfpvwphirxtfexszzckngpeauz', 'i_im_id': 1662}, {'i_id': 59275, 'i_name': 'joxapwcoottbarfjo', 'i_price': 71.20878869458735, 'i_data': 'tweekhdvzgwkrmntpcrtgngdzskzhfckfeqbio', 'i_im_id': 7604}, {'i_id': 88783, 'i_name': 'utuplvtoanopyzhykkvxxm', 'i_price': 82.65415910826509, 'i_data': 'ytjsvoklpkdweazjxhchzfcddbsbqbxi', 'i_im_id': 2906}  ... displaying 10 of 200000 total bound parameter sets ...  {'i_id': 60351, 'i_name': 'kjhxwxjszmtpeulpktqmp', 'i_price': 15.31778719710216, 'i_data': 'wuzmzzxthobhpgwcfwhckbtlf', 'i_im_id': 8846}, {'i_id': 91272, 'i_name': 'xzaiytcwaddpgye', 'i_price': 56.20498711072217, 'i_data': 'sfbuegxyzjipsmbjhkutkvvhnaxwhtekrgdhqrfwgxzrhn', 'i_im_id': 4700})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1782\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1782\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_executemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:951\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    950\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[0;32m--> 951\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m \u001b[43mxtras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutemany_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturning\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/psycopg2/extras.py:1270\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1269\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1270\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n",
      "\u001b[0;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"item_pkey\"\nDETAIL:  Key (i_id)=(41044) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m columns \u001b[38;5;241m=\u001b[39m inspector\u001b[38;5;241m.\u001b[39mget_columns(table_name)\n\u001b[1;32m     17\u001b[0m dtype \u001b[38;5;241m=\u001b[39m {col[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]: col[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns}\n\u001b[0;32m---> 18\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/core/generic.py:2963\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2808\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 2963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:697\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    695\u001b[0m     )\n\u001b[0;32m--> 697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:1739\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m   1729\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[1;32m   1730\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[1;32m   1731\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1736\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1737\u001b[0m )\n\u001b[0;32m-> 1739\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:1332\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:1322\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mSQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:950\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    949\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[0;32m--> 950\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     total_inserted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/pandas/io/sql.py:857\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    856\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[0;32m--> 857\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1289\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   1286\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m   1287\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/sql/elements.py:325\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    323\u001b[0m ):\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1481\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1471\u001b[0m )\n\u001b[1;32m   1473\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1474\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1475\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1480\u001b[0m )\n\u001b[0;32m-> 1481\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1495\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1496\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         ret,\n\u001b[1;32m   1501\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1845\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1842\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:2026\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2026\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2030\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/util/compat.py:207\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1782\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1782\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_executemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[1;32m   1786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:951\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    949\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    950\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[0;32m--> 951\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m \u001b[43mxtras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutemany_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturning\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_batch_page_size:\n",
      "File \u001b[0;32m~/.virtualenvs/default/lib/python3.8/site-packages/psycopg2/extras.py:1270\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1269\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1270\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[1;32m   1272\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"item_pkey\"\nDETAIL:  Key (i_id)=(41044) already exists.\n\n[SQL: INSERT INTO item (i_id, i_name, i_price, i_data, i_im_id) VALUES (%(i_id)s, %(i_name)s, %(i_price)s, %(i_data)s, %(i_im_id)s)]\n[parameters: ({'i_id': 71873, 'i_name': 'tdjtylgvvwtwgyxhj', 'i_price': 72.91484610436777, 'i_data': 'hdduohbpzmtpqcxxiaycdzefgntboifehfgalndewaznutnin', 'i_im_id': 8609}, {'i_id': 43783, 'i_name': 'xseowiihvcuoyjuncbdzril', 'i_price': 98.10781507092857, 'i_data': 'hdbklonizbqtywyjdxdvrbsbvfuk', 'i_im_id': 8364}, {'i_id': 47077, 'i_name': 'uqwguivweumqsbcntrvpglz', 'i_price': 65.60060731611074, 'i_data': 'jsuktpybndupslilzuyburjazxygajpbhunvloc', 'i_im_id': 749}, {'i_id': 50014, 'i_name': 'npyhkbushoybrzv', 'i_price': 72.86345612233407, 'i_data': 'auyhziljwvayekrxntiwdnazcynexga', 'i_im_id': 2899}, {'i_id': 85504, 'i_name': 'fsbwffneoyzyqriemtlgerz', 'i_price': 14.49870262950143, 'i_data': 'tyqyiwdkxxaqkyxleppjommfdzyojoqqyxfx', 'i_im_id': 4390}, {'i_id': 86847, 'i_name': 'knnjczehdtwwockwpv', 'i_price': 28.037320560710167, 'i_data': 'jncaoukfpvwphirxtfexszzckngpeauz', 'i_im_id': 1662}, {'i_id': 59275, 'i_name': 'joxapwcoottbarfjo', 'i_price': 71.20878869458735, 'i_data': 'tweekhdvzgwkrmntpcrtgngdzskzhfckfeqbio', 'i_im_id': 7604}, {'i_id': 88783, 'i_name': 'utuplvtoanopyzhykkvxxm', 'i_price': 82.65415910826509, 'i_data': 'ytjsvoklpkdweazjxhchzfcddbsbqbxi', 'i_im_id': 2906}  ... displaying 10 of 200000 total bound parameter sets ...  {'i_id': 60351, 'i_name': 'kjhxwxjszmtpeulpktqmp', 'i_price': 15.31778719710216, 'i_data': 'wuzmzzxthobhpgwcfwhckbtlf', 'i_im_id': 8846}, {'i_id': 91272, 'i_name': 'xzaiytcwaddpgye', 'i_price': 56.20498711072217, 'i_data': 'sfbuegxyzjipsmbjhkutkvvhnaxwhtekrgdhqrfwgxzrhn', 'i_im_id': 4700})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)"
     ]
    }
   ],
   "source": [
    "# Unfortunately, stream_results breaks pandas to_sql.\n",
    "execution_options = {'stream_results': True}\n",
    "execution_options = {}\n",
    "engine = create_engine('postgresql://benchbaseuser:benchbasepass@localhost/benchbasescaled', execution_options=execution_options)\n",
    "\n",
    "original_engine = create_engine('postgresql://benchbaseuser:benchbasepass@localhost/benchbase', execution_options=execution_options)\n",
    "inspector = Inspector.from_engine(original_engine)\n",
    "\n",
    "\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "for table in metadata.sorted_tables:\n",
    "    print(table_name)\n",
    "    df = scaled_tables[table.name]\n",
    "    columns = inspector.get_columns(table_name)\n",
    "    dtype = {col['name']: col['type'] for col in columns}\n",
    "    df.to_sql(table_name, con=engine, index=False, if_exists='append', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c59b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = MetaData(engine)\n",
    "metadata.reflect()\n",
    "\n",
    "for table_name in metadata.tables:\n",
    "    df = pd.read_sql_table(table_name, engine)#, chunksize=1000):\n",
    "    df = df.tail(420)\n",
    "\n",
    "    unchanging = np.array([df[c].nunique() == 1 or all(df[c].isna()) for c in df.columns])\n",
    "    objects = (~unchanging) & np.array([df[c].dtype == 'object' for c in df.columns])\n",
    "    monotonics = (~objects) & (~unchanging) & np.array([df[c].is_monotonic_increasing for c in df.columns])\n",
    "    randoms = ~(unchanging | objects | monotonics)\n",
    "\n",
    "    assert all(unchanging ^ objects ^ monotonics ^ randoms), f\"Error:\\n{unchanging}\\n{objects}\\n{monotonics}\\n{randoms}\"\n",
    "\n",
    "    u = df.loc[:, unchanging].reset_index(drop=True)\n",
    "\n",
    "    o = df.loc[:, objects].reset_index(drop=True)\n",
    "    # Shuffle the rows.\n",
    "    o = o.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    m = df.loc[:, monotonics].reset_index(drop=True)\n",
    "\n",
    "    r = df.loc[:, randoms].reset_index(drop=True)\n",
    "\n",
    "    forecast = {}\n",
    "\n",
    "    for df_subset in [m, r]:\n",
    "        for col in df_subset:\n",
    "            tsdf = pd.DataFrame()\n",
    "            tsdf['ds'] = pd.date_range(start=0, periods=len(df.index), freq='1D')\n",
    "            tsdf['y'] = df_subset[col]\n",
    "\n",
    "            prophet = NeuralProphet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
    "            prophet.fit(tsdf, freq=\"D\")\n",
    "            dff = prophet.make_future_dataframe(tsdf, periods=len(df.index))\n",
    "            predicted_prophet = prophet.predict(dff)['yhat1']\n",
    "            \n",
    "#             arima = pm.AutoARIMA()\n",
    "#             arima.fit(tsdf['y'])\n",
    "#             predicted_arima = arima.predict(n_periods=len(df.index))\n",
    "            \n",
    "#             ets = AutoETS(auto=True)\n",
    "#             ets.fit(tsdf['y'].astype(float, errors='ignore'))\n",
    "#             predicted_ets = ets.predict(tsdf.index.values + 1).values\n",
    "            \n",
    "            forecast[col] = predicted_prophet\n",
    "\n",
    "    forecast = pd.DataFrame(forecast)\n",
    "\n",
    "    fake = pd.concat([u,o,forecast], axis=1)[df.columns]\n",
    "\n",
    "\n",
    "    table = metadata.tables[table_name]\n",
    "    for col in table.columns:\n",
    "        if col.type.python_type == int:\n",
    "            fake[col.name] = fake[col.name].astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3]*100)\n",
    "ets = AutoETS(auto=True, trend='add', seasonal='add', sp=3)\n",
    "ets.fit(s)\n",
    "predicted_ets = ets.predict(s.index.values + 1)\n",
    "display(predicted_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b80242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3]*100)\n",
    "arima = pm.AutoARIMA()\n",
    "arima.fit(s)\n",
    "predicted_arima = arima.predict(n_periods=len(s.index))\n",
    "display(predicted_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5a132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3]*100)\n",
    "arima = AutoARIMA()\n",
    "arima.fit(s)\n",
    "predicted_arima = arima.predict(s.index.values + 1)\n",
    "display(predicted_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f6daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5]*10)\n",
    "ptf = PolynomialTrendForecaster(degree=3)\n",
    "ptf.fit(s)\n",
    "predicted_ptf = ptf.predict(s.index.values + 1)\n",
    "display(predicted_ptf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f585d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
